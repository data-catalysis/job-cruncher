{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitvenvvenva3138b71e4064f57aed9d81ac75a212c",
   "display_name": "Python 3.7.5 64-bit ('venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess, Vectorize (Word2Vec) and Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import spacy\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecto to DB and load Job post into DF\n",
    "con = sqlite3.connect(\"../collectors/data.sqlite3\")\n",
    "job_df = pd.read_sql_query(\"SELECT * from job_post\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>company</th>\n      <th>location</th>\n      <th>description</th>\n      <th>source</th>\n      <th>search_kw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Data Scientist</td>\n      <td>Aquatic Informatics</td>\n      <td>Vancouver, BC</td>\n      <td>Do you want a meaningful role in a company tha...</td>\n      <td>indeed.com</td>\n      <td>data scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Business Intelligence Analyst</td>\n      <td>GLENTEL</td>\n      <td>Burnaby, BC</td>\n      <td>Brand: Glentel Corporate\\nLocation: Burnaby Of...</td>\n      <td>indeed.com</td>\n      <td>data scientist</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Human Resources Data Scientist</td>\n      <td>Rio Tinto</td>\n      <td>Canada</td>\n      <td>2 x newly created Data Scientist opportunities...</td>\n      <td>indeed.com</td>\n      <td>data scientist</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lead - Human Resource Data Scientist</td>\n      <td>Rio Tinto</td>\n      <td>Canada</td>\n      <td>Newly created data science lead embedded withi...</td>\n      <td>indeed.com</td>\n      <td>data scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Machine Learning Engineer</td>\n      <td>Skycope Technologies Inc</td>\n      <td>Vancouver, BC</td>\n      <td>Who We are\\nFounded in 2016, Skycope Technolog...</td>\n      <td>indeed.com</td>\n      <td>data scientist</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   id                                 title                   company  \\\n0   1                        Data Scientist       Aquatic Informatics   \n1   2         Business Intelligence Analyst                   GLENTEL   \n2   3        Human Resources Data Scientist                 Rio Tinto   \n3   4  Lead - Human Resource Data Scientist                 Rio Tinto   \n4   5             Machine Learning Engineer  Skycope Technologies Inc   \n\n        location                                        description  \\\n0  Vancouver, BC  Do you want a meaningful role in a company tha...   \n1    Burnaby, BC  Brand: Glentel Corporate\\nLocation: Burnaby Of...   \n2         Canada  2 x newly created Data Scientist opportunities...   \n3         Canada  Newly created data science lead embedded withi...   \n4  Vancouver, BC  Who We are\\nFounded in 2016, Skycope Technolog...   \n\n       source       search_kw  \n0  indeed.com  data scientist  \n1  indeed.com  data scientist  \n2  indeed.com  data scientist  \n3  indeed.com  data scientist  \n4  indeed.com  data scientist  "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job titles\n",
    "job_titles = set(job_df['search_kw'].to_list())\n",
    "\n",
    "# Get job descriptions\n",
    "job_descriptions = job_df['description'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "({'data analyst', 'data engineer', 'data scientist'},\n 'Do you want a meaningful role in a company that is making a difference in the world? Do you want to ')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles, job_descriptions[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\".join(job_descriptions)\n",
    "corpus = corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Collecting en_core_web_lg==2.2.5\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n\u001b[K     |████████████████████████████████| 827.9 MB 31.8 MB/s \n\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from en_core_web_lg==2.2.5) (2.2.4)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.6.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\nRequirement already satisfied: thinc==7.4.0 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.45.0)\nRequirement already satisfied: setuptools in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (41.2.0)\nRequirement already satisfied: numpy>=1.15.0 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.1)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2019.11.28)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.25.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.8)\nRequirement already satisfied: zipp>=0.5 in /Users/Madan/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\nInstalling collected packages: en-core-web-lg\n    Running setup.py install for en-core-web-lg ... \u001b[?25ldone\n\u001b[?25hSuccessfully installed en-core-web-lg-2.2.5\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the model via spacy.load('en_core_web_lg')\n"
    }
   ],
   "source": [
    "# Download pretrained english model\n",
    "try:\n",
    "    import en_core_web_lg\n",
    "except:\n",
    "    !python -m spacy download en_core_web_lg\n",
    "    import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = [description.lower() for description in job_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()\n",
    "docs = list(nlp.pipe(job_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add(\"\\n\")\n",
    "\n",
    "# Preprocess the text\n",
    "def process_text(doc):\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words:\n",
    "            continue\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.lemma_ == '-PRON-':\n",
    "            continue\n",
    "        result.append(token.lemma_)\n",
    "    # return \" \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "spacy.tokens.doc.Doc"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = process_text(docs[0])\n",
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process every document\n",
    "for i in range(len(docs)):\n",
    "    docs[i] = process_text(docs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "JOB DESCRIPTION AFTER PREPROCESSING:\n\n['want', 'meaningful', 'role', 'company', 'make', 'difference', 'world', 'want', 'involve', 'important', 'environmental', 'resource', 'area', 'today', 'want', 'learn', 'involve', 'develop', 'deploy', 'machine']\n"
    }
   ],
   "source": [
    "print(\"JOB DESCRIPTION AFTER PREPROCESSING:\\n\")\n",
    "print(docs[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality of the resulting word vectors.\n",
    "num_features = 10\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 1\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(sentences=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Word2Vec vocabulary length: 14185\n"
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(49533679, 53844200)"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences=docs, total_examples=model.corpus_count, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'morning' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-2d0f6c2c95d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"morning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                 )\n\u001b[0;32m-> 1447\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \"\"\"\n\u001b[0;32m-> 1397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SFU/BigDataLab/job-cruncher/venv/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'morning' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.most_similar(\"morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([-2.0381882 , -0.53340995, -0.03796148, -4.180321  ,  1.1872729 ,\n        7.111414  , -3.855373  , -4.5400825 , -1.9881306 , -3.1982915 ],\n      dtype=float32)"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['stack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}